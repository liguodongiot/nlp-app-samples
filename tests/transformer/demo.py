from datasets import load_dataset, load_metric

# æ¯ä¸ªæ•°æ®é›†éƒ½ç”±ä¸€ä¸ªæ–‡æœ¬ç‰¹å¾ï¼ˆè¯„è®ºçš„æ–‡æœ¬ï¼‰å’Œä¸€ä¸ªæ ‡ç­¾ç‰¹å¾ï¼ˆè¡¨ç¤ºè¯„è®ºçš„å¥½åï¼‰ç»„æˆã€‚
task = "imdb"

dataset = load_dataset(task)

print(dataset)
"""
DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 25000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 25000
    })
    unsupervised: Dataset({
        features: ['text', 'label'],
        num_rows: 50000
    })
})
"""


########################

# IMDbæ•°æ®é›†çš„é€šç”¨åŸºå‡†æŒ‡æ ‡æ˜¯å‡†ç¡®ç‡ï¼Œæ‰€ä»¥è¿™é‡Œä½¿ç”¨ datasets åº“çš„ load_metric å‡½æ•°æ¥åŠ è½½ metric è„šæœ¬ï¼Œç¨åå¯ä»¥ä¸ compute æ–¹æ³•ä¸€èµ·ä½¿ç”¨ã€‚
metric = load_metric("accuracy")

metric.compute(predictions=[0,0,1,1], references=[0,1,1,1])
# {'accuracy': 0.75}


########################
# ä¸‹è½½çš„æ•°æ®é›†æœ‰è®­ç»ƒå’Œæµ‹è¯•æ‹†åˆ†ï¼Œä½†æˆ‘ä»¬è¿˜éœ€è¦æ‹†åˆ†å‡ºéªŒè¯é›†æ¥åˆ¤æ–­æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´è¡¨ç°ä»¥é¿å…è¿‡æ‹Ÿåˆã€‚
#
# ä½¿ç”¨train_test_split åº”ç”¨äº test_size = 0.3 è¿›è¡Œæ‹†åˆ†ï¼šè¿™ä¼šäº§ç”Ÿä¸€ä¸ªåŒ…å« 70% åŸå§‹æ ·æœ¬çš„æ–°è®­ç»ƒé›†å’Œä¸€ä¸ªåŒ…å« 30% åŸå§‹æ ·æœ¬çš„éªŒè¯é›†ã€‚
splitted_datasets = dataset["train"].train_test_split(test_size=0.3)
print(splitted_datasets)
"""
DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 17500
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 7500
    })
})
"""

# æ¥ä¸‹æ¥ä½¿ç”¨ Hugging Faceçš„AutoTokenizer ç±»åŠ è½½ BERT Tokenizerã€‚
#
# æœ¬æ–‡å®é™…ä¸ŠåŠ è½½ DistilBERT ä½œä¸º å¿«é€Ÿæ›¿ä»£æ–¹æ¡ˆï¼Œå¦‚æœéœ€è¦åŠ è½½ BERTï¼Œä»£ç åŸºæœ¬æ˜¯ç›¸åŒçš„ï¼ˆå³å°† distilbert-base-uncased æ›¿æ¢ä¸º Bert-base-uncasedï¼‰ã€‚
# DistilBERT æ˜¯ä¸€ç§å°å‹ã€å¿«é€Ÿã€å»‰ä»·å’Œè½»é‡çº§çš„ Transformer æ¨¡å‹ï¼Œé€šè¿‡è’¸é¦ BERT åŸºç¡€è¿›è¡Œè®­ç»ƒã€‚
# æ ¹æ® GLUE è¯­è¨€ç†è§£åŸºå‡†æµ‹è¯•ï¼Œå®ƒçš„å‚æ•°æ¯” Bert-base-uncased å°‘ 40%ï¼Œè¿è¡Œé€Ÿåº¦æé«˜ 60%ï¼ŒåŒæ—¶ä¿æŒ BERT 95% ä»¥ä¸Šçš„æ€§èƒ½ã€‚



from transformers import AutoTokenizer

model_checkpoint = "distilbert-base-uncased"

# use_fast: Whether or not to try to load the fast version of the tokenizer.
# Most of the tokenizers are available in two flavors: a full python
# implementation and a â€œFastâ€ implementation based on the Rust library ğŸ¤— Tokenizers.
# The â€œFastâ€ implementations allows a significant speed-up in particular
# when doing batched tokenization, and additional methods to map between the
# original string (character and words) and the token space.

# é»˜è®¤ï¼š/Users/liguodong/.cache/huggingface/transformers

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, cache_dir= "./temp",use_fast=True)

print(tokenizer(["Hello, this one sentence!"]))
# {'input_ids': [[101, 7592, 1010, 2023, 2028, 6251, 999, 102]], 'attention_mask':
# [[1, 1, 1, 1, 1, 1, 1, 1]]}
# input_ids: the tokenizer vocabulary indexes of the tokenized input sentence
# attention_mask: 0 if the corresponding input_id is padding, 1 otherwise

#  input_idsï¼šåˆ†è¯è¾“å…¥å¥å­çš„åˆ†è¯å™¨è¯æ±‡ç´¢å¼•ã€‚
#  attention_maskï¼šä¸€ä¸ªç”± 1 å’Œ 0 ç»„æˆçš„æ•°ç»„ï¼Œå…¶ä¸­ 0 è¡¨ç¤ºå‘ç”Ÿå¡«å……çš„ä½ç½®ã€‚

# input_ids å’Œ attention_mask éƒ½å°†è¢«è¾“å…¥ DistilBERT æ¨¡å‹ä¸­ã€‚



def preprocess_function_batch(examples):
    # truncation=True: truncate to the maximum acceptable input length for
    # the model.
    return tokenizer(examples["text"], truncation=True)

# batched=True: use this if you have a mapped function which can efficiently
# handle batches of inputs like the tokenizer
splitted_datasets_encoded = splitted_datasets.map(preprocess_function_batch, batched=True)
"""
DatasetDict({
    train: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 17500
    })
    test: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 7500
    })
})
"""

# ç°åœ¨å¯ä»¥ä½¿ç”¨ AutoModelForSequenceClassification ç±»åŠå…¶ from_pretrained æ–¹æ³•åŠ è½½é¢„è®­ç»ƒçš„ BERTã€‚
# è¿™é‡Œè¦ä½¿ç”¨num_label = 2 å‚æ•°ï¼Œå› ä¸ºç°åœ¨éœ€è¦åœ¨æ˜¯äºŒåˆ†ç±»ä»»åŠ¡ä¸Šå¾®è°ƒ BERTï¼Œ
# æˆ‘ä»¬å°†é‡æ–°ç”Ÿæˆçš„headéƒ¨åˆ†ï¼Œç”¨ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„å¸¦æœ‰ä¸¤ä¸ªæ ‡ç­¾çš„åˆ†ç±»å¤´æ›¿æ¢åŸå§‹å±‚ï¼ˆå…¶æƒé‡å°†åœ¨è®­ç»ƒæœŸé—´å­¦ä¹ ï¼‰





from transformers import TrainingArguments, Trainer
from transformers import AutoModelForSequenceClassification

# num_labels: number of labels to use in the last layer added to the model,
# typically for a classification task.

# The AutoModelForSequenceClassification class loads the
# DistilBertForSequenceClassification class as underlying model. Since
# AutoModelForSequenceClassification doesn't accept the parameter 'num_labels',
# it is passed to the underlying class DistilBertForSequenceClassification, which
# accepts it.

model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, cache_dir= "./temp")

# This will issue a warning about some of the pretrained weights not being used
# and some weights being randomly initialized. Thatâ€™s because we are throwing
# away the pretraining head of the BERT model to replace it with a classification
# head which is randomly initialized. We will fine-tune this model on our task,
# transferring the knowledge of the pretrained model to it (which is why doing
# this is called transfer learning).

# åœ¨ç¼–å†™è®­ç»ƒä»£ç ä¹‹å‰ï¼Œéœ€è¦å¯åŠ¨ TensorBoardï¼Œè¿™æ ·å¯ä»¥è·å¾—æ¨¡å‹çš„å®æ—¶è®­ç»ƒä¿¡æ¯ã€‚

# å¯åŠ¨ TensorBoard æ—¶ï¼Œlogdir å‚æ•°åº”è¯¥ä»£è¡¨ Hugging Face å†™å…¥æ¨¡å‹è®­ç»ƒæ—¥å¿—çš„ç›®å½•ã€‚

model_output_dir = f"{model_checkpoint}-finetuned-{task}"
print(model_output_dir) # distilbert-base-uncased-finetuned-imdb

# Start TensorBoard before training to monitor it in progress
# %load_ext tensorboard
# %tensorboard --logdir '{model_output_dir}'/runs

# å¯åŠ¨æ—¶ï¼ŒTensorBoard é¢æ¿å°†æ˜¾ç¤ºå½“å‰æ²¡æœ‰å¯ç”¨çš„ä»ªè¡¨æ¿ã€‚å¦‚æœåœ¨æ¨¡å‹è®­ç»ƒæœŸé—´åˆ·æ–°æ­¤é¡µé¢åˆ™ä¼šæŸ¥çœ‹åˆ°ä¸€äº›å®æ—¶çš„æ•°æ®ã€‚


# æ¥ä¸‹æ¥æ˜¯é…ç½®ä¸€äº›è®­ç»ƒå‚æ•°ã€‚ä»£ç ç‰‡æ®µä¸­å·²ç»ä¸ºæ¯ä¸ªå‚æ•°æ·»åŠ è¯´æ˜ã€‚

# output_dir å­˜å‚¨æœ€ç»ˆæ¨¡å‹çš„ä½ç½®ã€‚
# evaluation_strategyå’Œeval_stepsæ¯50ä¸ªè®­ç»ƒstepåœ¨éªŒè¯é›†ä¸ŠéªŒè¯è®­ç»ƒæ¨¡å‹ã€‚
# logging_strategy å’Œ logging_steps æ¯ 50 ä¸ªè®­ç»ƒstepä¿å­˜æ—¥å¿—ï¼ˆå°†ç”± TensorBoard å¯è§†åŒ–ï¼‰ã€‚
# save_strategy å’Œ save_steps è¡¨ç¤ºæ¯ 200 ä¸ªè®­ç»ƒstepä¿å­˜è®­ç»ƒæ¨¡å‹ã€‚
# learning_rate å­¦ä¹ ç‡ã€‚per_device_train_batch_size å’Œ per_device_eval_batch_size åˆ†åˆ«è¡¨ç¤ºåœ¨è®­ç»ƒå’ŒéªŒè¯æœŸé—´ä½¿ç”¨çš„æ‰¹å¤§å°ã€‚
# num_train_epochsè¡¨ç¤ºè®­ç»ƒçš„è½®æ¬¡æ•°ã€‚
# load_best_model_at_end è¡¨ç¤ºåœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—ä½¿ç”¨æ€§èƒ½æœ€å¥½çš„æ¨¡å‹ï¼ˆç”¨ metric_for_best_model æŒ‡å®šï¼‰çš„æ¨¡å‹ã€‚
# report_to å°†æ‰€æœ‰è®­ç»ƒå’ŒéªŒè¯çš„æ•°æ®æŠ¥å‘Šç»™ TensorBoardã€‚


args = TrainingArguments(
    # output_dir: directory where the model checkpoints will be saved.
    output_dir=model_output_dir,
    # evaluation_strategy (default "no"):
    # Possible values are:
    # "no": No evaluation is done during training.
    # "steps": Evaluation is done (and logged) every eval_steps.
    # "epoch": Evaluation is done at the end of each epoch.
    evaluation_strategy="steps",
    # eval_steps: Number of update steps between two evaluations if
    # evaluation_strategy="steps". Will default to the same value as
    # logging_steps if not set.
    eval_steps=50,
    # logging_strategy (default: "steps"): The logging strategy to adopt during
    # training (used to log training loss for example). Possible values are:
    # "no": No logging is done during training.
    # "epoch": Logging is done at the end of each epoch.
    # "steps": Logging is done every logging_steps.
    logging_strategy="steps",
    # logging_steps (default 500): Number of update steps between two logs if
    # logging_strategy="steps".
    logging_steps=50,
    # save_strategy (default "steps"):
    # The checkpoint save strategy to adopt during training. Possible values are:
    # "no": No save is done during training.
    # "epoch": Save is done at the end of each epoch.
    # "steps": Save is done every save_steps (default 500).
    save_strategy="steps",
    # save_steps (default: 500): Number of updates steps before two checkpoint
    # saves if save_strategy="steps".
    save_steps=200,
    # learning_rate (default 5e-5): The initial learning rate for AdamW optimizer.
    # Adam algorithm with weight decay fix as introduced in the paper
    # Decoupled Weight Decay Regularization.
    learning_rate=2e-5,
    # per_device_train_batch_size: The batch size per GPU/TPU core/CPU for training.
    per_device_train_batch_size=16,
    # per_device_eval_batch_size: The batch size per GPU/TPU core/CPU for evaluation.
    per_device_eval_batch_size=16,
    # num_train_epochs (default 3.0): Total number of training epochs to perform
    # (if not an integer, will perform the decimal part percents of the last epoch
    # before stopping training).
    num_train_epochs=1,
    # load_best_model_at_end (default False): Whether or not to load the best model
    # found during training at the end of training.
    load_best_model_at_end=True,
    # metric_for_best_model:
    # Use in conjunction with load_best_model_at_end to specify the metric to use
    # to compare two different models. Must be the name of a metric returned by
    # the evaluation with or without the prefix "eval_".
    metric_for_best_model="accuracy",
    # report_to:
    # The list of integrations to report the results and logs to. Supported
    # platforms are "azure_ml", "comet_ml", "mlflow", "tensorboard" and "wandb".
    # Use "all" to report to all integrations installed, "none" for no integrations.
    report_to="tensorboard"
)

# ç„¶åéœ€è¦å°†è¿™äº›è®­ç»ƒå‚æ•°ä¼ é€’ç»™ Trainer å¯¹è±¡ï¼Œ Trainer å¯¹è±¡è¢«å®ä¾‹åŒ–å°±å¯ä»¥ä½¿ç”¨ train æ–¹æ³•å¼€å§‹è®­ç»ƒã€‚

# Function that returns an untrained model to be trained
def model_init():
    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint,
                                                              num_labels=2)

# Function that will be called at the end of each evaluation phase on the whole
# arrays of predictions/labels to produce metrics.
def compute_metrics(eval_pred):
    # Predictions and labels are grouped in a namedtuple called EvalPrediction
    predictions, labels = eval_pred
    # Get the index with the highest prediction score (i.e. the predicted labels)
    predictions = np.argmax(predictions, axis=1)
    # Compare the predicted labels with the reference labels
    results =  metric.compute(predictions=predictions, references=labels)
    # results: a dictionary with string keys (the name of the metric) and float
    # values (i.e. the metric values)
    return results

# Since PyTorch does not provide a training loop, the ğŸ¤— Transformers library
# provides a Trainer API that is optimized for ğŸ¤— Transformers models, with a
# wide range of training options and with built-in features like logging,
# gradient accumulation, and mixed precision.
trainer = Trainer(
    # Function that returns the model to train. It's useful to use a function
    # instead of directly the model to make sure that we are always training
    # an untrained model from scratch.
    model_init=model_init,
    # The training arguments.
    args=args,
    # The training dataset.
    train_dataset=splitted_datasets_encoded["train"],
    # The evaluation dataset. We use a small subset of the validation set
    # composed of 150 samples to speed up computations...
    eval_dataset=splitted_datasets_encoded["test"].shuffle(42).select(range(150)),
    # Even though the training set and evaluation set are already tokenized, the
    # tokenizer is needed to pad the "input_ids" and "attention_mask" tensors
    # to the length managed by the model. It does so one batch at a time, to
    # use less memory as possible.
    tokenizer=tokenizer,
    # Function that will be called at the end of each evaluation phase on the whole
    # arrays of predictions/labels to produce metrics.
    compute_metrics=compute_metrics
)

# ... train the model!
trainer.train()

# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥åˆ·æ–° TensorBoard æ¥æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡çš„æ›´æ–°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œåªçœ‹åˆ°è®­ç»ƒé›†ä¸Šçš„æŸå¤±ã€éªŒè¯é›†ä¸Šçš„æŸå¤±å’ŒéªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡ã€‚

# Tokenize test set
dataset_test_encoded = dataset["test"].map(preprocess_function_batch, batched=True)
# Use the model to get predictions
test_predictions = trainer.predict(dataset_test_encoded)
# For each prediction, create the label with argmax
test_predictions_argmax = np.argmax(test_predictions[0], axis=1)
# Retrieve reference labels from test set
test_references = np.array(dataset["test"]["label"])
# Compute accuracy
metric.compute(predictions=test_predictions_argmax, references=test_references)
# {'accuracy': 0.91888}


